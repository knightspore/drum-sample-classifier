{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch, wandb, time\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,random_split,SubsetRandomSampler, ConcatDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Internal Imports\n",
    "from model import AudioClassifier\n",
    "from util import WavDataSet, SoundDS, PlotSpectrogram, predict, classes, classes_reverse\n",
    "from training_standard import training, inference  \n",
    "from training_k_fold import train_epoch, valid_epoch\n",
    "\n",
    "# GPU Setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Setup\n",
    "\n",
    "# # Create index\n",
    "# data = WavDataSet(\"D:/Documents/Samples/Beat Packs\")\n",
    "# print(data)\n",
    "\n",
    "# # Save CSV\n",
    "# data.csv(\"./data/edm_no_loops.csv\")\n",
    "\n",
    "# # Check Results \n",
    "# df = pd.read_csv(\"./data/edm_no_loops.csv\") \n",
    "# print(df.head())\n",
    "# print(f\"Dataset Length: {len(df)}\")\n",
    "\n",
    "# Create Pandas Dataframe from CSV\n",
    "df = pd.read_csv(\"./data/edm_no_loops.csv\")\n",
    "df = df[['path', 'class']]\n",
    "\n",
    "# Prepare Batches of Data using the Dataloader\n",
    "# Random 80:20 Split of Train:Validate\n",
    "myds = SoundDS(df)\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.67)\n",
    "num_val = num_items-num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard Training, Validation and Prediction\n",
    "batch_size = 64\n",
    "num_epochs = 1000\n",
    "lr = 0.002\n",
    "max_lr = 0.05\n",
    "\n",
    "model = AudioClassifier()\n",
    "model.to(device)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "training(model, train_dl, device=device, num_epochs=num_epochs, lr=lr, max_lr=max_lr, logger=None)\n",
    "inference(model, val_dl, device=device, logger=None)\n",
    "\n",
    "torch.save(model, f'models/model_lr{lr}_mlr{max_lr}_e{num_epochs}_b{batch_size}.pt')\n",
    "\n",
    "# Make a Prediction\n",
    "# predict(model, \"examples/TR-808Kick01.wav\", \"kick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K Fold Cross Validation\n",
    "batch_size = 64 \n",
    "num_epochs = 5 \n",
    "lr = 0.002\n",
    "dataset = ConcatDataset([train_ds, val_ds])\n",
    "\n",
    "# For Training, use a High Epoch and Low K\n",
    "# For Evaluation, use a Low Epoch and K of ~10\n",
    "k = 5\n",
    "torch.manual_seed(42)\n",
    "splits = KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf = {}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "    break\n",
    "    wandb.init(project=\"beatpack-ai\", entity=\"parabyl\", job_type='k-fold', name=f'fold_{fold}') # Running this line creates a new 'run'\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = {'train_loss': [], 'test_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler) \n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    model = AudioClassifier()\n",
    "    model.to(device)\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Load Previous Model\n",
    "    # cp = torch.load('models/zesty-salad-125_e512_f3_b128.pt')\n",
    "    # model.load_state_dict(cp['model_state_dict'])\n",
    "    # optimizer.load_state_dict(cp['optimizer_state_dict'])\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.002, steps_per_epoch=int(len(train_loader)), epochs=num_epochs, anneal_strategy='linear')\n",
    "    \n",
    "    print(f\"Fold {fold+1}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss, train_correct = train_epoch(model, device, train_loader, criterion, optimizer, scheduler)\n",
    "        test_loss, test_correct = valid_epoch(model, device, test_loader, criterion)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} AVG Training Loss: {train_loss:.3f} AVG Test Loss: {test_loss:.3f} AVG Training Acc: {train_acc:.2f}% AVG Test Acc: {test_acc:.2f}% Time: {time.time() - start_time:.2f}s\")\n",
    "        \n",
    "        wandb.log({\n",
    "            'Epoch': epoch+1, \n",
    "            'Avg. Training Loss': train_loss, \n",
    "            'Avg. Test Loss': test_loss, \n",
    "            'Avg. Training Accuracy': train_acc, \n",
    "            'Avg. Test Accuracy': test_acc})\n",
    "\n",
    "               \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "    foldperf[f'fold{fold}'] = history\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, f'models/{wandb.run.name}_e{num_epochs}_f{fold}_b{batch_size}.pt')\n",
    "    wandb.join()\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "# Test Report\n",
    "\n",
    "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
    "for f in range(0,k):\n",
    "    break\n",
    "    tl_f.append(np.mean(foldperf[f'fold{f}']['train_loss']))\n",
    "    testl_f.append(np.mean(foldperf[f'fold{f}']['test_loss']))\n",
    "\n",
    "    ta_f.append(np.mean(foldperf[f'fold{f}']['train_acc']))\n",
    "    testa_f.append(np.mean(foldperf[f'fold{f}']['test_acc']))\n",
    "\n",
    "print(f'K={k} fold cross validation complete')\n",
    "print(f\"Avg Training Loss: {np.mean(tl_f):.2f} Avg Test Loss: {np.mean(testl_f):.2f} Avg Training Acc: {np.mean(ta_f)} Avg Test Acc: {np.mean(testa_f)}\")     "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c7a21014fc0903b333c528e26b532495acabffc408f92f7990944da68b6f70a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
