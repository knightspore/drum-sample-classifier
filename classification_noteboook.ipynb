{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch, wandb, time\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,random_split,SubsetRandomSampler, ConcatDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Internal Imports\n",
    "from model import AudioClassifier\n",
    "from util import WavDataSet, SoundDS, PlotSpectrogram, predict, classes, classes_reverse\n",
    "from training_standard import training, inference  \n",
    "from training_k_fold import train_epoch, valid_epoch\n",
    "\n",
    "# GPU Setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Setup\n",
    "\n",
    "# # Create index\n",
    "# data = WavDataSet(\"D:/Documents/Samples/Beat Packs\")\n",
    "# print(data)\n",
    "\n",
    "# # Save CSV\n",
    "# data.csv(\"./data/edm_no_loops.csv\")\n",
    "\n",
    "# # Check Results \n",
    "# df = pd.read_csv(\"./data/edm_no_loops.csv\") \n",
    "# print(df.head())\n",
    "# print(f\"Dataset Length: {len(df)}\")\n",
    "\n",
    "# Create Pandas Dataframe from CSV\n",
    "df = pd.read_csv(\"./data/edm_no_loops.csv\")\n",
    "df = df[['path', 'class']]\n",
    "\n",
    "# Prepare Batches of Data using the Dataloader\n",
    "# Random 80:20 Split of Train:Validate\n",
    "myds = SoundDS(df)\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.67)\n",
    "num_val = num_items-num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard Training, Validation and Prediction\n",
    "# batch_size = 64\n",
    "# num_epochs = 5\n",
    "\n",
    "# model = AudioClassifier()\n",
    "# model.to(device)\n",
    "\n",
    "# train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "# val_dl = torch.utils.data.DataLoader(val_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "# training(model, train_dl, device=device, num_epochs=num_epochs, logger=None)\n",
    "# inference(model, val_dl, device=device, logger=None)\n",
    "\n",
    "# Make a Prediction\n",
    "# predict(model, \"examples/TR-808Kick01.wav\", \"kick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mparabyl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Development\\generative-beatpack\\wandb\\run-20220531_001714-3da72c35</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/parabyl/beatpack-ai/runs/3da72c35\" target=\"_blank\">fold_0</a></strong> to <a href=\"https://wandb.ai/parabyl/beatpack-ai\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch: 1/5 AVG Training Loss: 1.953 AVG Test Loss: 1.712 AVG Training Acc: 32.39% AVG Test Acc: 43.75% Time: 70.16s\n",
      "Epoch: 2/5 AVG Training Loss: 1.669 AVG Test Loss: 1.599 AVG Training Acc: 42.31% AVG Test Acc: 44.64% Time: 129.92s\n",
      "Epoch: 3/5 AVG Training Loss: 1.559 AVG Test Loss: 1.520 AVG Training Acc: 44.37% AVG Test Acc: 45.87% Time: 190.17s\n",
      "Epoch: 4/5 AVG Training Loss: 1.466 AVG Test Loss: 1.501 AVG Training Acc: 46.83% AVG Test Acc: 45.76% Time: 250.42s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Development\\generative-beatpack\\notebook.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/generative-beatpack/notebook.ipynb#ch0000012?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/generative-beatpack/notebook.ipynb#ch0000012?line=41'>42</a>\u001b[0m     train_loss, train_correct \u001b[39m=\u001b[39m train_epoch(model, device, train_loader, criterion, optimizer, scheduler)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Development/generative-beatpack/notebook.ipynb#ch0000012?line=42'>43</a>\u001b[0m     test_loss, test_correct \u001b[39m=\u001b[39m valid_epoch(model, device, test_loader, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/generative-beatpack/notebook.ipynb#ch0000012?line=44'>45</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader\u001b[39m.\u001b[39msampler)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Development/generative-beatpack/notebook.ipynb#ch0000012?line=45'>46</a>\u001b[0m     train_acc \u001b[39m=\u001b[39m train_correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader\u001b[39m.\u001b[39msampler) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[1;32md:\\Development\\generative-beatpack\\training_k_fold.py:50\u001b[0m, in \u001b[0;36mvalid_epoch\u001b[1;34m(model, device, dataloader, loss_fn)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/training_k_fold.py?line=46'>47</a>\u001b[0m total_prediction \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/training_k_fold.py?line=47'>48</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> <a href='file:///d%3A/Development/generative-beatpack/training_k_fold.py?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/training_k_fold.py?line=50'>51</a>\u001b[0m     \n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/training_k_fold.py?line=51'>52</a>\u001b[0m     \u001b[39m# Get inputs and labels on device\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/training_k_fold.py?line=52'>53</a>\u001b[0m     inputs \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/training_k_fold.py?line=53'>54</a>\u001b[0m     labels \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:578\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=574'>575</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=575'>576</a>\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=576'>577</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=577'>578</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=578'>579</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=579'>580</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=580'>581</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=581'>582</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:618\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=615'>616</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=616'>617</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=617'>618</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=618'>619</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataloader.py?line=619'>620</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:235\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataset.py?line=232'>233</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataset.py?line=233'>234</a>\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m--> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataset.py?line=234'>235</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataset.py?line=287'>288</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataset.py?line=288'>289</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/utils/data/dataset.py?line=289'>290</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32md:\\Development\\generative-beatpack\\util.py:118\u001b[0m, in \u001b[0;36mSoundDS.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Development/generative-beatpack/util.py?line=115'>116</a>\u001b[0m         rechan \u001b[39m=\u001b[39m AudioUtil\u001b[39m.\u001b[39mrechannel(reaud, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel) \n\u001b[0;32m    <a href='file:///d%3A/Development/generative-beatpack/util.py?line=116'>117</a>\u001b[0m         dur_aud \u001b[39m=\u001b[39m AudioUtil\u001b[39m.\u001b[39mpad_trunc(rechan, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mduration) \u001b[39m# sig, sr\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Development/generative-beatpack/util.py?line=117'>118</a>\u001b[0m         sgram \u001b[39m=\u001b[39m AudioUtil\u001b[39m.\u001b[39;49mspectro_gram(dur_aud, n_mels\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, n_fft\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m, hop_len\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///d%3A/Development/generative-beatpack/util.py?line=118'>119</a>\u001b[0m         aug_sgram \u001b[39m=\u001b[39m AudioUtil\u001b[39m.\u001b[39mspectro_augment(sgram, max_mask_pct\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, n_freq_masks\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, n_time_masks\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    <a href='file:///d%3A/Development/generative-beatpack/util.py?line=120'>121</a>\u001b[0m \t\t\t\t\u001b[39m# plot_spectrogram(sgram[0], title=f\"Random Sample Spec: {os.path.basename(audio_file)}\")\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Development/generative-beatpack/util.py?line=121'>122</a>\u001b[0m \t\t\t\t\u001b[39m# plot_spectrogram(aug_sgram[0], title=f\"Random Augmented Spec: {os.path.basename(audio_file)}\")\u001b[39;00m\n",
      "File \u001b[1;32md:\\Development\\generative-beatpack\\audio_util.py:90\u001b[0m, in \u001b[0;36mAudioUtil.spectro_gram\u001b[1;34m(aud, n_mels, n_fft, hop_len)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/audio_util.py?line=86'>87</a>\u001b[0m spec \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mMelSpectrogram(sr, n_fft\u001b[39m=\u001b[39mn_fft, hop_length\u001b[39m=\u001b[39mhop_len, n_mels\u001b[39m=\u001b[39mn_mels)(sig)\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/audio_util.py?line=88'>89</a>\u001b[0m \u001b[39m# Convert to dB\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/Development/generative-beatpack/audio_util.py?line=89'>90</a>\u001b[0m spec \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39;49mAmplitudeToDB(top_db\u001b[39m=\u001b[39;49mtop_db)(spec)\n\u001b[0;32m     <a href='file:///d%3A/Development/generative-beatpack/audio_util.py?line=90'>91</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (spec)\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1125'>1126</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1126'>1127</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1127'>1128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1128'>1129</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1129'>1130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1130'>1131</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1131'>1132</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torchaudio\\transforms\\_transforms.py:330\u001b[0m, in \u001b[0;36mAmplitudeToDB.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/transforms/_transforms.py?line=318'>319</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/transforms/_transforms.py?line=319'>320</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Numerically stable implementation from Librosa.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/transforms/_transforms.py?line=320'>321</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/transforms/_transforms.py?line=321'>322</a>\u001b[0m \u001b[39m    https://librosa.org/doc/latest/generated/librosa.amplitude_to_db.html\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/transforms/_transforms.py?line=327'>328</a>\u001b[0m \u001b[39m        Tensor: Output tensor in decibel scale.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/transforms/_transforms.py?line=328'>329</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/transforms/_transforms.py?line=329'>330</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mamplitude_to_DB(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultiplier, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mamin, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdb_multiplier, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_db)\n",
      "File \u001b[1;32mc:\\Users\\c\\anaconda3\\lib\\site-packages\\torchaudio\\functional\\functional.py:357\u001b[0m, in \u001b[0;36mamplitude_to_DB\u001b[1;34m(x, multiplier, amin, db_multiplier, top_db)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/functional/functional.py?line=353'>354</a>\u001b[0m packed_channels \u001b[39m=\u001b[39m shape[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m] \u001b[39mif\u001b[39;00m x_db\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/functional/functional.py?line=354'>355</a>\u001b[0m x_db \u001b[39m=\u001b[39m x_db\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, packed_channels, shape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m--> <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/functional/functional.py?line=356'>357</a>\u001b[0m x_db \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(x_db, (x_db\u001b[39m.\u001b[39;49mamax(dim\u001b[39m=\u001b[39;49m(\u001b[39m-\u001b[39;49m\u001b[39m3\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)) \u001b[39m-\u001b[39;49m top_db)\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/functional/functional.py?line=358'>359</a>\u001b[0m \u001b[39m# Repack batch\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/c/anaconda3/lib/site-packages/torchaudio/functional/functional.py?line=359'>360</a>\u001b[0m x_db \u001b[39m=\u001b[39m x_db\u001b[39m.\u001b[39mreshape(shape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K Fold Cross Validation\n",
    "batch_size = 64 \n",
    "num_epochs = 5 \n",
    "lr = 3e-4\n",
    "dataset = ConcatDataset([train_ds, val_ds])\n",
    "\n",
    "# For Training, use a High Epoch and Low K\n",
    "# For Evaluation, use a Low Epoch and K of ~10\n",
    "k = 5\n",
    "torch.manual_seed(42)\n",
    "splits = KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf = {}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "    wandb.init(project=\"beatpack-ai\", entity=\"parabyl\", job_type='k-fold', name=f'fold_{fold}') # Running this line creates a new 'run'\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = {'train_loss': [], 'test_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler) \n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    model = AudioClassifier()\n",
    "    model.to(device)\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Load Previous Model\n",
    "    # cp = torch.load('models/zesty-salad-125_e512_f3_b128.pt')\n",
    "    # model.load_state_dict(cp['model_state_dict'])\n",
    "    # optimizer.load_state_dict(cp['optimizer_state_dict'])\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.002, steps_per_epoch=int(len(train_loader)), epochs=num_epochs, anneal_strategy='linear')\n",
    "    \n",
    "    print(f\"Fold {fold+1}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss, train_correct = train_epoch(model, device, train_loader, criterion, optimizer, scheduler)\n",
    "        test_loss, test_correct = valid_epoch(model, device, test_loader, criterion)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} AVG Training Loss: {train_loss:.3f} AVG Test Loss: {test_loss:.3f} AVG Training Acc: {train_acc:.2f}% AVG Test Acc: {test_acc:.2f}% Time: {time.time() - start_time:.2f}s\")\n",
    "        \n",
    "        wandb.log({\n",
    "            'Epoch': epoch+1, \n",
    "            'Avg. Training Loss': train_loss, \n",
    "            'Avg. Test Loss': test_loss, \n",
    "            'Avg. Training Accuracy': train_acc, \n",
    "            'Avg. Test Accuracy': test_acc})\n",
    "\n",
    "               \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "    foldperf[f'fold{fold}'] = history\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, f'models/{wandb.run.name}_e{num_epochs}_f{fold}_b{batch_size}.pt')\n",
    "    wandb.join()\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "# Test Report\n",
    "\n",
    "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
    "for f in range(0,k):\n",
    "    tl_f.append(np.mean(foldperf[f'fold{f}']['train_loss']))\n",
    "    testl_f.append(np.mean(foldperf[f'fold{f}']['test_loss']))\n",
    "\n",
    "    ta_f.append(np.mean(foldperf[f'fold{f}']['train_acc']))\n",
    "    testa_f.append(np.mean(foldperf[f'fold{f}']['test_acc']))\n",
    "\n",
    "print(f'K={k} fold cross validation complete')\n",
    "print(f\"Avg Training Loss: {np.mean(tl_f):.2f} Avg Test Loss: {np.mean(testl_f):.2f} Avg Training Acc: {np.mean(ta_f)} Avg Test Acc: {np.mean(testa_f)}\")     "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c7a21014fc0903b333c528e26b532495acabffc408f92f7990944da68b6f70a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
